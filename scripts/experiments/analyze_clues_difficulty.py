#!/usr/bin/env python3
"""
é€šè¿‡çº¦æŸæ¡ä»¶æ•°é‡ï¼ˆæ ¼å­æ•°é‡ï¼‰åˆ†æé¢˜ç›®éš¾åº¦
"""

import re
import sys
from pathlib import Path
from collections import defaultdict

sys.path.insert(0, str(Path(__file__).parent.parent))

from sqlmodel import select
from utu.db.eval_datapoint import EvaluationSample
from utu.utils.sqlmodel_utils import SQLModelUtils


def extract_clues_count(question_text: str) -> int:
    """ä»é—®é¢˜æ–‡æœ¬ä¸­æå–çº¦æŸæ¡ä»¶ï¼ˆcluesï¼‰çš„æ•°é‡"""
    
    # æŸ¥æ‰¾ "## Clues:" æˆ– "Clues:" éƒ¨åˆ†
    clues_pattern = r'(?:##\s*)?Clues?\s*:\s*\n'
    clues_match = re.search(clues_pattern, question_text, re.IGNORECASE)
    
    if not clues_match:
        # å¦‚æœæ²¡æœ‰æ˜ç¡®çš„Clueséƒ¨åˆ†ï¼Œå°è¯•æŸ¥æ‰¾ç¼–å·çš„çº¦æŸæ¡ä»¶
        # æ ¼å¼å¦‚ "1. ..." æˆ– "1) ..."
        numbered_clues = re.findall(r'^\s*\d+[\.\)]\s+', question_text, re.MULTILINE)
        return len(numbered_clues)
    
    # æå–Clueséƒ¨åˆ†ä¹‹åçš„å†…å®¹
    clues_start = clues_match.end()
    clues_text = question_text[clues_start:]
    
    # æŸ¥æ‰¾æ‰€æœ‰ç¼–å·çš„çº¦æŸæ¡ä»¶
    # æ ¼å¼: "1. ..." æˆ– "1) ..." æˆ– "1 ..."
    numbered_pattern = r'^\s*(\d+)[\.\)]\s+'
    clues = re.findall(numbered_pattern, clues_text, re.MULTILINE)
    
    if clues:
        # è·å–æœ€å¤§çš„ç¼–å·
        max_num = max(int(num) for num in clues)
        return max_num
    
    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç¼–å·ï¼Œå°è¯•è®¡ç®—è¡Œæ•°ï¼ˆæ’é™¤ç©ºè¡Œï¼‰
    lines = [line.strip() for line in clues_text.split('\n') if line.strip()]
    return len(lines)


def analyze_clues_difficulty(exp_id: str, output_file: str):
    """åˆ†æçº¦æŸæ¡ä»¶æ•°é‡ä¸éš¾åº¦çš„å…³ç³»"""
    
    print(f"\n{'='*80}")
    print(f"åˆ†æçº¦æŸæ¡ä»¶æ•°é‡ï¼ˆæ ¼å­æ•°é‡ï¼‰ä¸éš¾åº¦çš„å…³ç³»")
    print(f"{'='*80}\n")
    print(f"å®éªŒ ID: {exp_id}\n")
    
    with SQLModelUtils.create_session() as session:
        samples = list(session.exec(
            select(EvaluationSample).where(
                EvaluationSample.exp_id == exp_id
            ).order_by(EvaluationSample.dataset_index)
        ))
        
        if not samples:
            print(f"æœªæ‰¾åˆ°æ•°æ®")
            return
        
        # æŒ‰é—®é¢˜åˆ†ç»„
        problem_to_samples = defaultdict(list)
        for sample in samples:
            key = sample.raw_question or sample.question
            problem_to_samples[key].append(sample)
        
        # è·å–æ‰€æœ‰é—®é¢˜ï¼ˆæŒ‰å‡ºç°é¡ºåºï¼‰
        all_problems = list(problem_to_samples.keys())
        
        print(f"æ€»é—®é¢˜æ•°: {len(all_problems)}\n")
        
        # åˆ†ææ¯ä¸ªé—®é¢˜
        problem_data = []
        for idx, problem in enumerate(all_problems, 1):
            problem_samples = problem_to_samples[problem]
            sample = problem_samples[0]
            
            # æå–çº¦æŸæ¡ä»¶æ•°é‡
            clues_count = extract_clues_count(problem)
            
            # è®¡ç®—æ­£ç¡®ç‡
            correct_count = sum(1 for s in problem_samples if s.reward and s.reward > 0.5)
            accuracy = correct_count / len(problem_samples) * 100
            
            problem_data.append({
                'id': idx,
                'clues_count': clues_count,
                'correct_count': correct_count,
                'accuracy': accuracy,
                'question': problem[:200]  # ä¿å­˜å‰200å­—ç¬¦ç”¨äºæ£€æŸ¥
            })
            
            print(f"é¢˜ç›® {idx}: {clues_count} ä¸ªçº¦æŸæ¡ä»¶, æ­£ç¡®ç‡ {accuracy:.2f}%")
        
        print(f"\n{'='*80}\n")
        
        # æŒ‰çº¦æŸæ¡ä»¶æ•°é‡åˆ†ç»„ç»Ÿè®¡
        clues_to_problems = defaultdict(list)
        for p in problem_data:
            clues_to_problems[p['clues_count']].append(p)
        
        # ç”ŸæˆæŠ¥å‘Š
        output_lines = []
        output_lines.append("# çº¦æŸæ¡ä»¶æ•°é‡ï¼ˆæ ¼å­æ•°é‡ï¼‰ä¸éš¾åº¦å…³ç³»åˆ†æ\n\n")
        output_lines.append("**å®éªŒ ID**: `{}`\n\n".format(exp_id))
        output_lines.append("---\n\n")
        
        # æ€»ä½“ç»Ÿè®¡
        output_lines.append("## ğŸ“Š æ€»ä½“ç»Ÿè®¡\n\n")
        avg_clues = sum(p['clues_count'] for p in problem_data) / len(problem_data)
        min_clues = min(p['clues_count'] for p in problem_data)
        max_clues = max(p['clues_count'] for p in problem_data)
        
        output_lines.append(f"- **æ€»é¢˜ç›®æ•°**: {len(problem_data)}\n")
        output_lines.append(f"- **å¹³å‡çº¦æŸæ¡ä»¶æ•°**: {avg_clues:.1f}\n")
        output_lines.append(f"- **æœ€å°‘çº¦æŸæ¡ä»¶**: {min_clues}\n")
        output_lines.append(f"- **æœ€å¤šçº¦æŸæ¡ä»¶**: {max_clues}\n\n")
        output_lines.append("---\n\n")
        
        # æŒ‰çº¦æŸæ¡ä»¶æ•°é‡åˆ†ç»„
        output_lines.append("## ğŸ“ˆ æŒ‰çº¦æŸæ¡ä»¶æ•°é‡åˆ†ç»„ç»Ÿè®¡\n\n")
        output_lines.append("| çº¦æŸæ¡ä»¶æ•° | é¢˜ç›®æ•°é‡ | å¹³å‡æ­£ç¡®ç‡ | é¢˜ç›®ç¼–å· |\n")
        output_lines.append("|-----------|---------|-----------|---------|\n")
        
        for clues_count in sorted(clues_to_problems.keys()):
            problems_in_group = clues_to_problems[clues_count]
            avg_accuracy = sum(p['accuracy'] for p in problems_in_group) / len(problems_in_group)
            problem_ids = ', '.join(str(p['id']) for p in sorted(problems_in_group, key=lambda x: x['id']))
            output_lines.append(f"| {clues_count} | {len(problems_in_group)} | {avg_accuracy:.2f}% | {problem_ids} |\n")
        
        output_lines.append("\n---\n\n")
        
        # è¯¦ç»†åˆ—è¡¨
        output_lines.append("## ğŸ“‹ æ‰€æœ‰é¢˜ç›®è¯¦ç»†ä¿¡æ¯\n\n")
        output_lines.append("| é¢˜ç›®ç¼–å· | çº¦æŸæ¡ä»¶æ•° | æ­£ç¡®æ•°/æ€»æ•° | æ­£ç¡®ç‡ |\n")
        output_lines.append("|---------|-----------|------------|--------|\n")
        
        for p in sorted(problem_data, key=lambda x: x['clues_count']):
            output_lines.append(f"| {p['id']} | {p['clues_count']} | {p['correct_count']}/32 | {p['accuracy']:.2f}% |\n")
        
        output_lines.append("\n---\n\n")
        
        # ç›¸å…³æ€§åˆ†æ
        output_lines.append("## ğŸ” ç›¸å…³æ€§åˆ†æ\n\n")
        
        # è®¡ç®—ç›¸å…³ç³»æ•°ï¼ˆç®€å•ç‰ˆæœ¬ï¼‰
        clues_counts = [p['clues_count'] for p in problem_data]
        accuracies = [p['accuracy'] for p in problem_data]
        
        correlation = calculate_correlation(clues_counts, accuracies)
        output_lines.append(f"**çº¦æŸæ¡ä»¶æ•°é‡ä¸æ­£ç¡®ç‡çš„ç›¸å…³ç³»æ•°**: {correlation:.3f}\n\n")
        
        if correlation < -0.3:
            output_lines.append("ğŸ“‰ **è´Ÿç›¸å…³è¾ƒå¼º**: çº¦æŸæ¡ä»¶è¶Šå¤šï¼Œæ­£ç¡®ç‡è¶Šä½ï¼ˆé¢˜ç›®è¶Šéš¾ï¼‰\n\n")
        elif correlation > 0.3:
            output_lines.append("ğŸ“ˆ **æ­£ç›¸å…³è¾ƒå¼º**: çº¦æŸæ¡ä»¶è¶Šå¤šï¼Œæ­£ç¡®ç‡è¶Šé«˜ï¼ˆé¢˜ç›®è¶Šå®¹æ˜“ï¼‰\n\n")
        else:
            output_lines.append("ğŸ“Š **ç›¸å…³æ€§è¾ƒå¼±**: çº¦æŸæ¡ä»¶æ•°é‡ä¸æ­£ç¡®ç‡å…³ç³»ä¸æ˜æ˜¾\n\n")
        
        # æŒ‰çº¦æŸæ¡ä»¶æ•°é‡åŒºé—´çš„ç»Ÿè®¡
        output_lines.append("### æŒ‰çº¦æŸæ¡ä»¶æ•°é‡åŒºé—´ç»Ÿè®¡\n\n")
        output_lines.append("| çº¦æŸæ¡ä»¶æ•°åŒºé—´ | é¢˜ç›®æ•°é‡ | å¹³å‡æ­£ç¡®ç‡ | é¢˜ç›®ç¼–å· |\n")
        output_lines.append("|--------------|---------|-----------|---------|\n")
        
        intervals = [
            (0, 10, "0-10"),
            (10, 12, "10-12"),
            (12, 15, "12-15"),
            (15, 20, "15-20"),
            (20, 100, "20+")
        ]
        
        for start, end, label in intervals:
            problems_in_interval = [p for p in problem_data if start <= p['clues_count'] < end]
            if problems_in_interval:
                avg_acc = sum(p['accuracy'] for p in problems_in_interval) / len(problems_in_interval)
                problem_ids = ', '.join(str(p['id']) for p in sorted(problems_in_interval, key=lambda x: x['id']))
                output_lines.append(f"| {label} | {len(problems_in_interval)} | {avg_acc:.2f}% | {problem_ids} |\n")
        
        output_lines.append("\n---\n\n")
        
        # å…³é”®å‘ç°
        output_lines.append("## ğŸ’¡ å…³é”®å‘ç°\n\n")
        
        # æ‰¾å‡ºçº¦æŸæ¡ä»¶æœ€å°‘å’Œæœ€å¤šçš„é¢˜ç›®
        min_clues_problems = [p for p in problem_data if p['clues_count'] == min_clues]
        max_clues_problems = [p for p in problem_data if p['clues_count'] == max_clues]
        
        output_lines.append(f"### çº¦æŸæ¡ä»¶æœ€å°‘çš„é¢˜ç›® ({min_clues}ä¸ª)\n\n")
        for p in min_clues_problems:
            output_lines.append(f"- é¢˜ç›® {p['id']}: æ­£ç¡®ç‡ {p['accuracy']:.2f}%\n")
        
        output_lines.append(f"\n### çº¦æŸæ¡ä»¶æœ€å¤šçš„é¢˜ç›® ({max_clues}ä¸ª)\n\n")
        for p in max_clues_problems:
            output_lines.append(f"- é¢˜ç›® {p['id']}: æ­£ç¡®ç‡ {p['accuracy']:.2f}%\n")
        
        output_lines.append("\n")
        
        # å…³æ³¨çš„5é“é¢˜ç›®
        target_problems = [4, 5, 11, 22, 23]
        output_lines.append("### å…³æ³¨çš„5é“é¢˜ç›®ï¼ˆ4, 5, 11, 22, 23ï¼‰\n\n")
        output_lines.append("| é¢˜ç›®ç¼–å· | çº¦æŸæ¡ä»¶æ•° | æ­£ç¡®ç‡ |\n")
        output_lines.append("|---------|-----------|--------|\n")
        
        for target_id in target_problems:
            if target_id <= len(problem_data):
                p = problem_data[target_id - 1]
                output_lines.append(f"| {p['id']} | {p['clues_count']} | {p['accuracy']:.2f}% |\n")
        
        # ä¿å­˜æŠ¥å‘Š
        output_text = ''.join(output_lines)
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(output_text)
        
        print(f"âœ… åˆ†ææŠ¥å‘Šå·²ç”Ÿæˆ: {output_file}")


def calculate_correlation(x, y):
    """è®¡ç®—çš®å°”é€Šç›¸å…³ç³»æ•°"""
    n = len(x)
    if n == 0:
        return 0
    
    mean_x = sum(x) / n
    mean_y = sum(y) / n
    
    numerator = sum((x[i] - mean_x) * (y[i] - mean_y) for i in range(n))
    denominator_x = sum((x[i] - mean_x) ** 2 for i in range(n))
    denominator_y = sum((y[i] - mean_y) ** 2 for i in range(n))
    
    if denominator_x == 0 or denominator_y == 0:
        return 0
    
    return numerator / ((denominator_x * denominator_y) ** 0.5)


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="åˆ†æçº¦æŸæ¡ä»¶æ•°é‡ä¸éš¾åº¦çš„å…³ç³»")
    parser.add_argument(
        "--exp_id",
        type=str,
        default="logic_zebralogic_test_eval",
        help="å®éªŒ ID"
    )
    parser.add_argument(
        "--output",
        type=str,
        default="çº¦æŸæ¡ä»¶æ•°é‡ä¸éš¾åº¦åˆ†æ.md",
        help="è¾“å‡ºæ–‡ä»¶"
    )
    
    args = parser.parse_args()
    
    analyze_clues_difficulty(args.exp_id, args.output)















































































