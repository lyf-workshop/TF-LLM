#!/usr/bin/env python3
"""
åˆ†ææŒ‡å®šé¢˜ç›®çš„å…±åŒç‰¹å¾
"""

import sys
from pathlib import Path
from sqlmodel import select
from collections import defaultdict
import re

sys.path.insert(0, str(Path(__file__).parent.parent))

from utu.db.eval_datapoint import EvaluationSample
from utu.utils.sqlmodel_utils import SQLModelUtils


def analyze_commonality(exp_id: str, problem_indices: list[int]):
    """åˆ†æé¢˜ç›®çš„å…±åŒç‰¹å¾"""
    
    print(f"\n{'='*80}")
    print(f"åˆ†æé¢˜ç›®å…±åŒç‰¹å¾")
    print(f"{'='*80}\n")
    print(f"å®éªŒ ID: {exp_id}")
    print(f"é¢˜ç›®ç¼–å·: {problem_indices}\n")
    
    with SQLModelUtils.create_session() as session:
        samples = list(session.exec(
            select(EvaluationSample).where(
                EvaluationSample.exp_id == exp_id
            ).order_by(EvaluationSample.dataset_index)
        ))
        
        if not samples:
            print(f"æœªæ‰¾åˆ°æ•°æ®")
            return
        
        # æŒ‰é—®é¢˜åˆ†ç»„
        problem_to_samples = defaultdict(list)
        for sample in samples:
            key = sample.raw_question or sample.question
            problem_to_samples[key].append(sample)
        
        # è·å–æ‰€æœ‰é—®é¢˜ï¼ˆæŒ‰å‡ºç°é¡ºåºï¼‰
        all_problems = list(problem_to_samples.keys())
        
        print(f"æ€»é—®é¢˜æ•°: {len(all_problems)}\n")
        
        # æå–æŒ‡å®šé¢˜ç›®
        target_problems = []
        for idx in problem_indices:
            if idx < 1 or idx > len(all_problems):
                print(f"âš ï¸ é¢˜ç›® {idx} è¶…å‡ºèŒƒå›´")
                continue
            problem = all_problems[idx - 1]
            target_problems.append((idx, problem))
        
        print(f"{'='*80}\n")
        print("ğŸ“‹ é¢˜ç›®å†…å®¹åˆ†æ\n")
        print(f"{'='*80}\n")
        
        # åˆ†ææ¯ä¸ªé¢˜ç›®
        all_attributes = []
        all_constraints = []
        problem_types = []
        
        for idx, problem in target_problems:
            print(f"### é¢˜ç›® {idx}\n")
            print(f"```\n{problem[:800]}\n```\n")
            
            # æå–å±æ€§
            attributes = re.findall(r'Each person has (?:a |an )?unique (?:type of |level of |favorite )?([^:]+):', problem)
            attributes.extend(re.findall(r'People have unique ([^:]+):', problem))
            attributes.extend(re.findall(r'Everyone has (?:something |a )?unique ([^:]+):', problem))
            attributes.extend(re.findall(r'The ([^:]+) (?:in different houses |are )?unique:', problem))
            attributes.extend(re.findall(r'Each person (?:has |prefers |lives in )?(?:a |an )?unique ([^:]+):', problem))
            attributes.extend(re.findall(r'They all have (?:a |an )?unique ([^:]+):', problem))
            
            if attributes:
                print(f"**å±æ€§**: {', '.join(attributes[:10])}\n")
                all_attributes.extend(attributes)
            
            # æå–çº¦æŸæ¡ä»¶æ•°é‡
            constraint_lines = [line for line in problem.split('\n') if line.strip() and ('is' in line.lower() or 'has' in line.lower() or 'lives' in line.lower())]
            all_constraints.extend(constraint_lines)
            
            # åˆ¤æ–­é—®é¢˜ç±»å‹
            if '4 houses' in problem.lower():
                problem_types.append('4æ ‹æˆ¿å­')
            
            print(f"**çº¦æŸæ¡ä»¶è¡Œæ•°**: {len(constraint_lines)}\n")
            print("---\n\n")
        
        # å…±åŒç‰¹å¾åˆ†æ
        print(f"{'='*80}\n")
        print("ğŸ” å…±åŒç‰¹å¾åˆ†æ\n")
        print(f"{'='*80}\n")
        
        print("### 1. é—®é¢˜ç»“æ„\n")
        print(f"- âœ… æ‰€æœ‰é¢˜ç›®éƒ½æ˜¯ **4æ ‹æˆ¿å­** çš„é€»è¾‘æ¨ç†é—®é¢˜")
        print(f"- âœ… éƒ½æ˜¯çº¦æŸæ»¡è¶³é—®é¢˜ (Constraint Satisfaction Problem)")
        print(f"- âœ… éƒ½æ¶‰åŠå¤šä¸ªå±æ€§çš„å”¯ä¸€æ€§åˆ†é…\n")
        
        print("### 2. å±æ€§ç‰¹å¾\n")
        attribute_counts = defaultdict(int)
        for attr in all_attributes:
            attr_clean = attr.strip().lower()
            attribute_counts[attr_clean] += 1
        
        print("**å¸¸è§å±æ€§** (å‡ºç°é¢‘ç‡):")
        for attr, count in sorted(attribute_counts.items(), key=lambda x: x[1], reverse=True)[:15]:
            print(f"- `{attr}`: {count}æ¬¡")
        print()
        
        print("### 3. çº¦æŸå¤æ‚åº¦\n")
        print(f"- å¹³å‡çº¦æŸæ¡ä»¶è¡Œæ•°: {len(all_constraints) / len(target_problems):.1f} è¡Œ")
        print(f"- æ€»çº¦æŸæ¡ä»¶æ•°: {len(all_constraints)} æ¡\n")
        
        print("### 4. éš¾åº¦ç‰¹å¾\n")
        print("è¿™äº›é¢˜ç›®å¯èƒ½å…·æœ‰ä»¥ä¸‹å…±åŒéš¾åº¦ç‰¹å¾:")
        print("- éœ€è¦åŒæ—¶è€ƒè™‘å¤šä¸ªçº¦æŸæ¡ä»¶")
        print("- éœ€è¦é€æ­¥æ¨ç†å’Œæ’é™¤")
        print("- å¯èƒ½å­˜åœ¨éšå«çš„çº¦æŸå…³ç³»")
        print("- éœ€è¦ç»´æŠ¤å¤šä¸ªå±æ€§çš„åˆ†é…çŠ¶æ€\n")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ç‰¹å®šçš„å±æ€§ç»„åˆ
        print("### 5. å±æ€§ç»„åˆåˆ†æ\n")
        unique_combinations = set()
        for idx, problem in target_problems:
            attrs = []
            # æå–æ‰€æœ‰å±æ€§å
            for match in re.finditer(r'(?:Each person|People|Everyone|They all) (?:has|have|prefers|lives in) (?:a |an |something )?unique (?:type of |level of |favorite )?([^:]+):', problem):
                attrs.append(match.group(1).strip().lower())
            if attrs:
                unique_combinations.add(tuple(sorted(attrs)))
        
        print(f"**ä¸åŒçš„å±æ€§ç»„åˆæ•°**: {len(unique_combinations)}")
        for i, combo in enumerate(unique_combinations, 1):
            print(f"{i}. {', '.join(combo[:5])}...")
        print()


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="åˆ†æé¢˜ç›®çš„å…±åŒç‰¹å¾")
    parser.add_argument(
        "--exp_id",
        type=str,
        default="logic_zebralogic_test_eval",
        help="å®éªŒ ID"
    )
    parser.add_argument(
        "--problems",
        type=int,
        nargs="+",
        default=[4, 5, 11, 22, 23],
        help="é¢˜ç›®ç¼–å·ï¼ˆç©ºæ ¼åˆ†éš”ï¼‰"
    )
    
    args = parser.parse_args()
    
    analyze_commonality(args.exp_id, args.problems)















































































