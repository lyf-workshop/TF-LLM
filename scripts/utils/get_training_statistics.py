#!/usr/bin/env python3
"""
è·å–è®­ç»ƒå‰åçš„è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯

ç”¨æ³•:
    python scripts/get_training_statistics.py --baseline_exp_id <baseline_id> --practice_exp_id <practice_id>
"""

import sys
from pathlib import Path
from sqlmodel import select, func
from collections import defaultdict

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from utu.db.eval_datapoint import EvaluationSample
from utu.utils.sqlmodel_utils import SQLModelUtils


def calculate_pass_at_k(samples, k):
    """è®¡ç®— Pass@K"""
    problem_to_samples = defaultdict(list)
    for sample in samples:
        key = sample.raw_question or sample.question
        problem_to_samples[key].append(sample)
    
    solved_problems = 0
    for problem, problem_samples in problem_to_samples.items():
        # å–å‰kä¸ªæ ·æœ¬
        samples_k = problem_samples[:k]
        # å¦‚æœä»»æ„ä¸€ä¸ªæ­£ç¡®ï¼Œåˆ™é—®é¢˜è¢«è§£å†³
        if any(s.reward and s.reward > 0.5 for s in samples_k):
            solved_problems += 1
    
    return solved_problems / len(problem_to_samples) if problem_to_samples else 0.0


def get_statistics(baseline_exp_id: str, practice_exp_id: str):
    """è·å–è®­ç»ƒå‰åçš„è¯¦ç»†ç»Ÿè®¡"""
    
    print("\n" + "=" * 80)
    print("ğŸ“Š è®­ç»ƒå‰åè¯¦ç»†ç»Ÿè®¡")
    print("=" * 80)
    print(f"\nBaseline å®éªŒ: {baseline_exp_id}")
    print(f"Practice å®éªŒ: {practice_exp_id}")
    print()
    
    with SQLModelUtils.create_session() as session:
        # è·å– baseline æ•°æ®
        baseline_samples = list(session.exec(
            select(EvaluationSample).where(
                EvaluationSample.exp_id == baseline_exp_id
            )
        ))
        
        # è·å– practice æ•°æ®
        practice_samples = list(session.exec(
            select(EvaluationSample).where(
                EvaluationSample.exp_id == practice_exp_id
            )
        ))
        
        if not baseline_samples:
            print(f"âŒ æœªæ‰¾åˆ° Baseline æ•°æ®")
            return
        
        if not practice_samples:
            print(f"âŒ æœªæ‰¾åˆ° Practice æ•°æ®")
            return
        
        # Baseline ç»Ÿè®¡
        print("=" * 80)
        print("ğŸ“ˆ Baseline (è®­ç»ƒå‰) ç»Ÿè®¡")
        print("=" * 80)
        
        baseline_total = len(baseline_samples)
        baseline_correct = sum(1 for s in baseline_samples if s.reward and s.reward > 0.5)
        baseline_accuracy = baseline_correct / baseline_total if baseline_total > 0 else 0.0
        
        # æŒ‰é—®é¢˜åˆ†ç»„
        baseline_problems = defaultdict(list)
        for sample in baseline_samples:
            key = sample.raw_question or sample.question
            baseline_problems[key].append(sample)
        
        baseline_solved_problems = sum(
            1 for problem_samples in baseline_problems.values()
            if any(s.reward and s.reward > 0.5 for s in problem_samples)
        )
        baseline_total_problems = len(baseline_problems)
        
        baseline_pass_at_32 = calculate_pass_at_k(baseline_samples, 32)
        
        print(f"\næ ·æœ¬çº§åˆ«ç»Ÿè®¡:")
        print(f"  - æ€»æ ·æœ¬æ•°: {baseline_total}")
        print(f"  - æ­£ç¡®æ ·æœ¬æ•°: {baseline_correct}")
        print(f"  - é”™è¯¯æ ·æœ¬æ•°: {baseline_total - baseline_correct}")
        print(f"  - å‡†ç¡®ç‡: {baseline_accuracy:.2%}")
        
        print(f"\né—®é¢˜çº§åˆ«ç»Ÿè®¡:")
        print(f"  - æ€»é—®é¢˜æ•°: {baseline_total_problems}")
        print(f"  - å·²è§£å†³é—®é¢˜æ•°: {baseline_solved_problems}")
        print(f"  - æœªè§£å†³é—®é¢˜æ•°: {baseline_total_problems - baseline_solved_problems}")
        print(f"  - æ¯é¢˜å¹³å‡æ ·æœ¬æ•°: {baseline_total / baseline_total_problems:.1f}")
        print(f"  - Pass@32: {baseline_pass_at_32:.2%}")
        
        # Practice ç»Ÿè®¡
        print("\n" + "=" * 80)
        print("ğŸ“ˆ Practice (è®­ç»ƒå) ç»Ÿè®¡")
        print("=" * 80)
        
        practice_total = len(practice_samples)
        practice_correct = sum(1 for s in practice_samples if s.reward and s.reward > 0.5)
        practice_accuracy = practice_correct / practice_total if practice_total > 0 else 0.0
        
        # æŒ‰é—®é¢˜åˆ†ç»„
        practice_problems = defaultdict(list)
        for sample in practice_samples:
            key = sample.raw_question or sample.question
            practice_problems[key].append(sample)
        
        practice_solved_problems = sum(
            1 for problem_samples in practice_problems.values()
            if any(s.reward and s.reward > 0.5 for s in problem_samples)
        )
        practice_total_problems = len(practice_problems)
        
        practice_pass_at_32 = calculate_pass_at_k(practice_samples, 32)
        
        print(f"\næ ·æœ¬çº§åˆ«ç»Ÿè®¡:")
        print(f"  - æ€»æ ·æœ¬æ•°: {practice_total}")
        print(f"  - æ­£ç¡®æ ·æœ¬æ•°: {practice_correct}")
        print(f"  - é”™è¯¯æ ·æœ¬æ•°: {practice_total - practice_correct}")
        print(f"  - å‡†ç¡®ç‡: {practice_accuracy:.2%}")
        
        print(f"\né—®é¢˜çº§åˆ«ç»Ÿè®¡:")
        print(f"  - æ€»é—®é¢˜æ•°: {practice_total_problems}")
        print(f"  - å·²è§£å†³é—®é¢˜æ•°: {practice_solved_problems}")
        print(f"  - æœªè§£å†³é—®é¢˜æ•°: {practice_total_problems - practice_solved_problems}")
        print(f"  - æ¯é¢˜å¹³å‡æ ·æœ¬æ•°: {practice_total / practice_total_problems:.1f}")
        print(f"  - Pass@32: {practice_pass_at_32:.2%}")
        
        # å¯¹æ¯”
        print("\n" + "=" * 80)
        print("ğŸ“Š å¯¹æ¯”åˆ†æ")
        print("=" * 80)
        
        accuracy_improvement = practice_accuracy - baseline_accuracy
        pass_at_32_improvement = practice_pass_at_32 - baseline_pass_at_32
        solved_improvement = practice_solved_problems - baseline_solved_problems
        
        print(f"\næ ·æœ¬çº§åˆ«å¯¹æ¯”:")
        print(f"  - å‡†ç¡®ç‡: {baseline_accuracy:.2%} â†’ {practice_accuracy:.2%} ({accuracy_improvement:+.2%})")
        print(f"  - æ­£ç¡®æ ·æœ¬: {baseline_correct}/{baseline_total} â†’ {practice_correct}/{practice_total}")
        
        print(f"\né—®é¢˜çº§åˆ«å¯¹æ¯”:")
        print(f"  - Pass@32: {baseline_pass_at_32:.2%} â†’ {practice_pass_at_32:.2%} ({pass_at_32_improvement:+.2%})")
        print(f"  - å·²è§£å†³é—®é¢˜: {baseline_solved_problems}/{baseline_total_problems} â†’ {practice_solved_problems}/{practice_total_problems} ({solved_improvement:+d})")
        
        # å˜åŒ–åˆ†æ
        print(f"\nå˜åŒ–åˆ†æ:")
        if accuracy_improvement > 0:
            print(f"  âœ… æ ·æœ¬å‡†ç¡®ç‡æå‡äº† {accuracy_improvement:.2%}")
        elif accuracy_improvement < 0:
            print(f"  âŒ æ ·æœ¬å‡†ç¡®ç‡ä¸‹é™äº† {abs(accuracy_improvement):.2%}")
        else:
            print(f"  â¡ï¸ æ ·æœ¬å‡†ç¡®ç‡ä¿æŒä¸å˜")
        
        if pass_at_32_improvement > 0:
            print(f"  âœ… Pass@32 æå‡äº† {pass_at_32_improvement:.2%}")
        elif pass_at_32_improvement < 0:
            print(f"  âŒ Pass@32 ä¸‹é™äº† {abs(pass_at_32_improvement):.2%}")
        else:
            print(f"  â¡ï¸ Pass@32 ä¿æŒä¸å˜")
        
        if solved_improvement > 0:
            print(f"  âœ… å¤šè§£å†³äº† {solved_improvement} ä¸ªé—®é¢˜")
        elif solved_improvement < 0:
            print(f"  âŒ å°‘è§£å†³äº† {abs(solved_improvement)} ä¸ªé—®é¢˜")
        else:
            print(f"  â¡ï¸ è§£å†³çš„é—®é¢˜æ•°é‡ç›¸åŒ")
        
        print("\n" + "=" * 80)
        print()


def main():
    import argparse
    
    parser = argparse.ArgumentParser(
        description="è·å–è®­ç»ƒå‰åçš„è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯"
    )
    parser.add_argument(
        "--baseline_exp_id",
        type=str,
        default="logic_zebralogic_test_eval",
        help="Baseline å®éªŒ ID"
    )
    parser.add_argument(
        "--practice_exp_id",
        type=str,
        default="logic_practice_zebralogic_test_eval",
        help="Practice å®éªŒ ID"
    )
    
    args = parser.parse_args()
    
    get_statistics(args.baseline_exp_id, args.practice_exp_id)


if __name__ == "__main__":
    main()


