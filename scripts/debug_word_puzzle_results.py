#!/usr/bin/env python3
"""
æ£€æŸ¥ word_puzzle_practice_eval ä¸ºä»€ä¹ˆå‡†ç¡®ç‡ä¸º0

ç”¨æ³•:
    uv run python scripts/debug_word_puzzle_results.py
"""
import sys
from pathlib import Path

project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from sqlmodel import select
from utu.db import EvaluationSample
from utu.utils import SQLModelUtils, get_logger

logger = get_logger(__name__)


def analyze_results():
    """åˆ†æ word_puzzle_practice_eval çš„ç»“æœ"""
    
    exp_id = "word_puzzle_practice_eval"
    
    print("\n" + "=" * 80)
    print(f"åˆ†æå®éªŒ: {exp_id}")
    print("=" * 80)
    
    with SQLModelUtils.create_session() as session:
        # è·å–æ‰€æœ‰æ ·æœ¬
        samples = list(session.exec(
            select(EvaluationSample)
            .where(EvaluationSample.exp_id == exp_id)
            .limit(5)
        ))
        
        if not samples:
            print(f"\nâŒ æœªæ‰¾åˆ°å®éªŒ {exp_id} çš„æ•°æ®")
            return
        
        print(f"\nğŸ“Š æ‰¾åˆ° {len(samples)} ä¸ªæ ·æœ¬ï¼ˆæ˜¾ç¤ºå‰5ä¸ªï¼‰")
        print()
        
        for i, sample in enumerate(samples, 1):
            print(f"\n{'='*80}")
            print(f"æ ·æœ¬ {i}:")
            print(f"{'='*80}")
            print(f"é—®é¢˜: {sample.raw_question[:100]}...")
            print(f"ç­”æ¡ˆ: {sample.response[:200] if sample.response else 'None'}...")
            print(f"æ­£ç¡®: {sample.correct}")
            print(f"å¥–åŠ±: {sample.reward}")
            print(f"æå–çš„ç­”æ¡ˆ: {sample.extracted_final_answer}")
            print(f"å…ƒæ•°æ®: {sample.meta}")
            
            # æ£€æŸ¥trajectories
            if sample.trajectories:
                import json
                try:
                    trajs = json.loads(sample.trajectories)
                    print(f"è½¨è¿¹æ•°é‡: {len(trajs)}")
                    if trajs:
                        print(f"ç¬¬ä¸€ä¸ªè½¨è¿¹: {str(trajs[0])[:200]}...")
                except:
                    print(f"è½¨è¿¹: {sample.trajectories[:200]}...")
        
        # ç»Ÿè®¡ä¿¡æ¯
        print(f"\n{'='*80}")
        print("ç»Ÿè®¡ä¿¡æ¯:")
        print(f"{'='*80}")
        
        all_samples = list(session.exec(
            select(EvaluationSample)
            .where(EvaluationSample.exp_id == exp_id)
        ))
        
        correct_count = sum(1 for s in all_samples if s.correct)
        total = len(all_samples)
        
        print(f"æ€»æ ·æœ¬æ•°: {total}")
        print(f"æ­£ç¡®æ•°: {correct_count}")
        print(f"å‡†ç¡®ç‡: {correct_count / total * 100:.2f}%")
        
        # åˆ†æå¤±è´¥åŸå› 
        print(f"\nå¤±è´¥åŸå› åˆ†æ:")
        no_response = sum(1 for s in all_samples if not s.response or s.response.strip() == "")
        no_extracted = sum(1 for s in all_samples if not s.extracted_final_answer)
        zero_reward = sum(1 for s in all_samples if s.reward == 0)
        
        print(f"  - æ— å“åº”: {no_response}")
        print(f"  - æœªæå–ç­”æ¡ˆ: {no_extracted}")
        print(f"  - å¥–åŠ±ä¸º0: {zero_reward}")
        
        # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†è®­ç»ƒåçš„agent
        print(f"\næ£€æŸ¥é…ç½®:")
        sample = all_samples[0]
        if sample.meta:
            print(f"  - meta: {sample.meta}")


if __name__ == "__main__":
    analyze_results()

















