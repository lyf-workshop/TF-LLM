#!/usr/bin/env python3
"""
åˆ†æç­”æ¡ˆæ ¼å¼é—®é¢˜ - è¯Šæ–­éªŒè¯å™¨æ˜¯å¦å› ä¸ºæ ¼å¼é—®é¢˜å¯¼è‡´åˆ¤æ–­é”™è¯¯

è¿™ä¸ªè„šæœ¬ä¼šï¼š
1. æå–å®é™…ç­”æ¡ˆå’Œæ ‡å‡†ç­”æ¡ˆ
2. æ˜¾ç¤ºç­”æ¡ˆæ ¼å¼
3. æµ‹è¯•éªŒè¯å™¨çš„è§£æè¿‡ç¨‹
4. è¯Šæ–­æ ¼å¼é—®é¢˜
"""

import json
import re
import sys
from pathlib import Path

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from utu.db import EvaluationSample
from utu.practice.verify.logic import verify_func
from utu.utils.sqlmodel_utils import SQLModelUtils
from sqlmodel import Session, select


def _try_parse_dict_or_json(text: str) -> any:
    """å°è¯•è§£æä¸º dict æˆ– JSON"""
    if not text:
        return None
    
    # å…ˆå°è¯• JSON
    try:
        return json.loads(text)
    except (json.JSONDecodeError, ValueError):
        pass
    
    # å°è¯• Python dict (å•å¼•å·)
    try:
        # å°†å•å¼•å·æ›¿æ¢ä¸ºåŒå¼•å·
        json_text = text.replace("'", '"')
        return json.loads(json_text)
    except (json.JSONDecodeError, ValueError):
        pass
    
    return None


def extract_answer_debug(response: str) -> tuple[str, dict]:
    """
    è°ƒè¯•ç‰ˆçš„ç­”æ¡ˆæå–å‡½æ•°ï¼Œè¿”å›æå–è¿‡ç¨‹çš„è¯¦ç»†ä¿¡æ¯
    
    Returns:
        (extracted_answer, debug_info)
    """
    debug_info = {
        "original_response": response[:500],
        "steps": []
    }
    
    if not response:
        debug_info["steps"].append("å“åº”ä¸ºç©º")
        return "", debug_info
    
    # Step 1: æŸ¥æ‰¾ <answer> æ ‡ç­¾
    answer_pattern = r'<answer>(.*?)</answer>'
    answer_match = re.search(answer_pattern, response, re.DOTALL | re.IGNORECASE)
    
    if answer_match:
        answer_text = answer_match.group(1).strip()
        debug_info["steps"].append(f"æ‰¾åˆ° <answer> æ ‡ç­¾ï¼Œå†…å®¹é•¿åº¦: {len(answer_text)}")
        debug_info["answer_text"] = answer_text[:300]
    else:
        debug_info["steps"].append("æœªæ‰¾åˆ° <answer> æ ‡ç­¾ï¼Œä½¿ç”¨å®Œæ•´å“åº”")
        answer_text = response
        debug_info["answer_text"] = answer_text[:300]
    
    # Step 2: æå– \boxed{} å†…å®¹
    boxed_pattern = r'\\boxed\{(.*?)\}'
    boxed_match = re.search(boxed_pattern, answer_text, re.DOTALL)
    
    if boxed_match:
        extracted = boxed_match.group(1).strip()
        debug_info["steps"].append(f"æ‰¾åˆ° \\boxed{{}} æ ¼å¼ï¼Œå†…å®¹: {extracted[:100]}")
        debug_info["extracted_from_boxed"] = extracted[:200]
        answer_text = extracted
    else:
        debug_info["steps"].append("æœªæ‰¾åˆ° \\boxed{} æ ¼å¼")
    
    # Step 3: å°è¯•è§£æ JSON
    # ç§»é™¤å¯èƒ½çš„ markdown ä»£ç å—
    if answer_text.startswith('```'):
        debug_info["steps"].append("å‘ç° markdown ä»£ç å—ï¼Œå°è¯•ç§»é™¤")
        answer_text = re.sub(r'^```(?:json)?\s*\n', '', answer_text)
        answer_text = re.sub(r'\n```\s*$', '', answer_text)
    
    parsed = _try_parse_dict_or_json(answer_text)
    if parsed is not None:
        debug_info["steps"].append(f"æˆåŠŸè§£æä¸º JSON/dictï¼Œç±»å‹: {type(parsed).__name__}")
        debug_info["parsed_json"] = str(parsed)[:200]
        return json.dumps(parsed, ensure_ascii=False), debug_info
    else:
        debug_info["steps"].append("JSON/dict è§£æå¤±è´¥")
    
    # Step 4: è¿”å›æ¸…ç†åçš„æ–‡æœ¬
    debug_info["steps"].append("è¿”å›æ¸…ç†åçš„æ–‡æœ¬ç­”æ¡ˆ")
    return answer_text.strip(), debug_info


def analyze_single_sample(sample: EvaluationSample, sample_id: int = 1):
    """è¯¦ç»†åˆ†æå•ä¸ªæ ·æœ¬çš„ç­”æ¡ˆæ ¼å¼"""
    print("\n" + "="*80)
    print(f"æ ·æœ¬ {sample_id} è¯¦ç»†åˆ†æ")
    print("="*80)
    
    # åŸºæœ¬ä¿¡æ¯
    print(f"\nã€åŸºæœ¬ä¿¡æ¯ã€‘")
    print(f"å®éªŒID: {sample.exp_id}")
    print(f"åŸå§‹ Reward: {sample.reward}")
    print(f"åŸå§‹åˆ¤æ–­: {'âœ“ æ­£ç¡®' if sample.reward >= 1.0 else 'âœ— é”™è¯¯'}")
    
    # é—®é¢˜
    print(f"\nã€é—®é¢˜ã€‘")
    print(f"{sample.raw_question[:300]}...")
    
    # æ ‡å‡†ç­”æ¡ˆåˆ†æ
    print(f"\nã€æ ‡å‡†ç­”æ¡ˆã€‘")
    print(f"é•¿åº¦: {len(sample.correct_answer) if sample.correct_answer else 0}")
    
    if sample.correct_answer:
        # å°è¯•è§£ææ ‡å‡†ç­”æ¡ˆ
        try:
            gt_parsed = json.loads(sample.correct_answer)
            print(f"æ ¼å¼: JSON ({type(gt_parsed).__name__})")
            print(f"å†…å®¹é¢„è§ˆ: {json.dumps(gt_parsed, ensure_ascii=False)[:200]}...")
            if isinstance(gt_parsed, dict):
                print(f"JSON é”®: {list(gt_parsed.keys())}")
        except:
            print(f"æ ¼å¼: æ–‡æœ¬")
            print(f"å†…å®¹: {sample.correct_answer[:200]}...")
    
    # æ¨¡å‹ç­”æ¡ˆåˆ†æ
    print(f"\nã€æ¨¡å‹ç­”æ¡ˆã€‘")
    print(f"é•¿åº¦: {len(sample.response) if sample.response else 0}")
    
    if sample.response:
        # æ˜¾ç¤ºå®Œæ•´å“åº”çš„å…³é”®éƒ¨åˆ†
        print(f"\nåŸå§‹å“åº”ï¼ˆå‰500å­—ç¬¦ï¼‰:")
        print("-" * 80)
        print(sample.response[:500])
        print("-" * 80)
        
        # è°ƒè¯•ç‰ˆç­”æ¡ˆæå–
        extracted, debug_info = extract_answer_debug(sample.response)
        
        print(f"\nç­”æ¡ˆæå–è¿‡ç¨‹:")
        for i, step in enumerate(debug_info["steps"], 1):
            print(f"  {i}. {step}")
        
        print(f"\næœ€ç»ˆæå–çš„ç­”æ¡ˆ:")
        print(f"é•¿åº¦: {len(extracted)}")
        print(f"å†…å®¹: {extracted[:300]}...")
        
        # å°è¯•è§£ææå–çš„ç­”æ¡ˆ
        extracted_parsed = _try_parse_dict_or_json(extracted)
        if extracted_parsed is not None:
            print(f"æ ¼å¼: JSON/dict ({type(extracted_parsed).__name__})")
            if isinstance(extracted_parsed, dict):
                print(f"JSON é”®: {list(extracted_parsed.keys())}")
        else:
            print(f"æ ¼å¼: æ–‡æœ¬")
    
    # é‡æ–°éªŒè¯
    print(f"\nã€é‡æ–°éªŒè¯ã€‘")
    try:
        result = verify_func(sample)
        new_reward = result["reward"]
        print(f"æ–° Reward: {new_reward}")
        print(f"æ–°åˆ¤æ–­: {'âœ“ æ­£ç¡®' if new_reward >= 1.0 else 'âœ— é”™è¯¯'}")
        
        if "reasoning" in result and result["reasoning"]:
            print(f"Reasoning: {result['reasoning'][:200]}...")
        
        # åˆ¤æ–­æ˜¯å¦åŒ¹é…
        original_ok = sample.reward >= 1.0
        new_ok = new_reward >= 1.0
        
        if original_ok != new_ok:
            print(f"\nâš ï¸  åˆ¤æ–­ä¸ä¸€è‡´ï¼")
            if new_ok and not original_ok:
                print(f"åŸæœ¬åˆ¤æ–­ä¸ºé”™è¯¯ï¼Œä½†é‡æ–°éªŒè¯ä¸ºæ­£ç¡®")
                print(f"â†’ å¯èƒ½åŸå› : åŸå§‹è¯„ä¼°æ—¶çš„éªŒè¯é€»è¾‘æœ‰é—®é¢˜")
            else:
                print(f"åŸæœ¬åˆ¤æ–­ä¸ºæ­£ç¡®ï¼Œä½†é‡æ–°éªŒè¯ä¸ºé”™è¯¯")
                print(f"â†’ å¯èƒ½åŸå› : å½“å‰éªŒè¯å™¨æ›´ä¸¥æ ¼æˆ–ç­”æ¡ˆæ ¼å¼æœ‰å˜åŒ–")
        else:
            print(f"\nâœ“ åˆ¤æ–­ä¸€è‡´")
            
    except Exception as e:
        print(f"éªŒè¯å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    
    # æ ¼å¼è¯Šæ–­
    print(f"\nã€æ ¼å¼è¯Šæ–­ã€‘")
    
    issues = []
    
    # æ£€æŸ¥ <answer> æ ‡ç­¾
    if sample.response and "<answer>" not in sample.response.lower():
        issues.append("ç¼ºå°‘ <answer> æ ‡ç­¾")
    
    # æ£€æŸ¥ \boxed{}
    if sample.response and "\\boxed{" not in sample.response:
        issues.append("ç¼ºå°‘ \\boxed{} æ ¼å¼")
    
    # æ£€æŸ¥ JSON æ ¼å¼
    if sample.response:
        if "<answer>" in sample.response.lower():
            answer_match = re.search(r'<answer>(.*?)</answer>', sample.response, re.DOTALL | re.IGNORECASE)
            if answer_match:
                answer_content = answer_match.group(1).strip()
                # å°è¯•ä» boxed ä¸­æå–
                boxed_match = re.search(r'\\boxed\{(.*?)\}', answer_content, re.DOTALL)
                if boxed_match:
                    answer_content = boxed_match.group(1).strip()
                # ä½¿ç”¨ _try_parse_dict_or_json æ£€æŸ¥
                parsed = _try_parse_dict_or_json(answer_content)
                if parsed is None:
                    issues.append("JSON æ ¼å¼é”™è¯¯")
    
    if issues:
        print("å‘ç°çš„é—®é¢˜:")
        for issue in issues:
            print(f"  âœ— {issue}")
    else:
        print("âœ“ æ ¼å¼æ£€æŸ¥é€šè¿‡")


def compare_answer_formats(exp_id: str, limit: int = 5):
    """å¯¹æ¯”å¤šä¸ªæ ·æœ¬çš„ç­”æ¡ˆæ ¼å¼"""
    print("\n" + "="*80)
    print(f"ç­”æ¡ˆæ ¼å¼å¯¹æ¯”åˆ†æ: {exp_id}")
    print("="*80)
    
    engine = SQLModelUtils.get_engine()
    
    with Session(engine) as session:
        # è·å–é”™è¯¯çš„æ ·æœ¬
        stmt = select(EvaluationSample).where(
            EvaluationSample.exp_id == exp_id
        ).where(
            EvaluationSample.reward < 1.0
        ).limit(limit)
        
        wrong_samples = list(session.exec(stmt).all())
        
        if not wrong_samples:
            print("æœªæ‰¾åˆ°é”™è¯¯æ ·æœ¬")
            return
        
        print(f"\nåˆ†æ {len(wrong_samples)} ä¸ªé”™è¯¯æ ·æœ¬çš„ç­”æ¡ˆæ ¼å¼\n")
        
        # ç»Ÿè®¡æ ¼å¼é—®é¢˜
        format_stats = {
            "missing_answer_tag": 0,
            "missing_boxed": 0,
            "json_parse_error": 0,
            "format_ok_but_wrong": 0,
            "total": len(wrong_samples)
        }
        
        for i, sample in enumerate(wrong_samples, 1):
            has_answer_tag = "<answer>" in (sample.response or "").lower()
            has_boxed = "\\boxed{" in (sample.response or "")
            
            # å°è¯•æå–å’Œè§£æ
            can_parse_json = False
            if sample.response:
                try:
                    extracted, _ = extract_answer_debug(sample.response)
                    parsed = _try_parse_dict_or_json(extracted)
                    can_parse_json = (parsed is not None)
                except:
                    pass
            
            # ç»Ÿè®¡
            if not has_answer_tag:
                format_stats["missing_answer_tag"] += 1
            if not has_boxed:
                format_stats["missing_boxed"] += 1
            if not can_parse_json and sample.correct_answer:
                # æ£€æŸ¥æ ‡å‡†ç­”æ¡ˆæ˜¯å¦æ˜¯ JSON
                gt_parsed = _try_parse_dict_or_json(sample.correct_answer)
                if gt_parsed is not None:
                    # æ ‡å‡†ç­”æ¡ˆæ˜¯ JSONï¼Œä½†æ¨¡å‹ç­”æ¡ˆä¸æ˜¯
                    format_stats["json_parse_error"] += 1
            if has_answer_tag and has_boxed and can_parse_json:
                format_stats["format_ok_but_wrong"] += 1
            
            # æ˜¾ç¤ºç®€è¦ä¿¡æ¯
            status = "âœ“" if (has_answer_tag and has_boxed) else "âœ—"
            print(f"{status} æ ·æœ¬ {i}: ", end="")
            if not has_answer_tag:
                print("ç¼º<answer> ", end="")
            if not has_boxed:
                print("ç¼º\\boxed{{}} ", end="")
            if not can_parse_json:
                print("JSONè§£æå¤±è´¥ ", end="")
            if has_answer_tag and has_boxed and can_parse_json:
                print("æ ¼å¼æ­£å¸¸ä½†ç­”æ¡ˆé”™è¯¯", end="")
            print()
        
        # æ‰“å°ç»Ÿè®¡
        print("\n" + "="*80)
        print("æ ¼å¼é—®é¢˜ç»Ÿè®¡")
        print("="*80)
        print(f"æ€»é”™è¯¯æ ·æœ¬æ•°: {format_stats['total']}")
        print(f"ç¼ºå°‘ <answer> æ ‡ç­¾: {format_stats['missing_answer_tag']} ({format_stats['missing_answer_tag']/format_stats['total']*100:.1f}%)")
        print(f"ç¼ºå°‘ \\boxed{{}} æ ¼å¼: {format_stats['missing_boxed']} ({format_stats['missing_boxed']/format_stats['total']*100:.1f}%)")
        print(f"JSON è§£æå¤±è´¥: {format_stats['json_parse_error']} ({format_stats['json_parse_error']/format_stats['total']*100:.1f}%)")
        print(f"æ ¼å¼æ­£å¸¸ä½†ç­”æ¡ˆé”™è¯¯: {format_stats['format_ok_but_wrong']} ({format_stats['format_ok_but_wrong']/format_stats['total']*100:.1f}%)")
        
        print("\n" + "="*80)
        print("è¯Šæ–­ç»“è®º")
        print("="*80)
        
        format_issue_rate = (format_stats['missing_answer_tag'] + format_stats['missing_boxed'] + format_stats['json_parse_error']) / format_stats['total']
        
        if format_issue_rate > 0.5:
            print("ğŸš¨ ä¸¥é‡çš„æ ¼å¼é—®é¢˜ï¼")
            print(f"   {format_issue_rate*100:.1f}% çš„é”™è¯¯æ˜¯ç”±äºç­”æ¡ˆæ ¼å¼é—®é¢˜")
            print("   å»ºè®®: æ£€æŸ¥ agent çš„ promptï¼Œç¡®ä¿è¦æ±‚æ­£ç¡®çš„ç­”æ¡ˆæ ¼å¼")
        elif format_issue_rate > 0.2:
            print("âš ï¸  ä¸­ç­‰ç¨‹åº¦çš„æ ¼å¼é—®é¢˜")
            print(f"   {format_issue_rate*100:.1f}% çš„é”™è¯¯æ˜¯ç”±äºç­”æ¡ˆæ ¼å¼é—®é¢˜")
            print("   å»ºè®®: ä¼˜åŒ– agent çš„ç­”æ¡ˆæ ¼å¼æŒ‡å¯¼")
        elif format_issue_rate > 0:
            print("âœ“ è½»å¾®çš„æ ¼å¼é—®é¢˜")
            print(f"   åªæœ‰ {format_issue_rate*100:.1f}% çš„é”™è¯¯æ˜¯ç”±äºæ ¼å¼é—®é¢˜")
            print(f"   {format_stats['format_ok_but_wrong']} ä¸ªæ ·æœ¬æ ¼å¼æ­£ç¡®ä½†ç­”æ¡ˆé”™è¯¯")
            print("   ä¸»è¦é—®é¢˜æ˜¯æ¨ç†é”™è¯¯ï¼Œä¸æ˜¯æ ¼å¼é—®é¢˜")
        else:
            print("âœ“ æ— æ ¼å¼é—®é¢˜")
            print("   æ‰€æœ‰é”™è¯¯æ ·æœ¬çš„æ ¼å¼éƒ½æ­£ç¡®")
            print("   é—®é¢˜å‡ºåœ¨æ¨ç†é€»è¾‘ï¼Œä¸æ˜¯ç­”æ¡ˆæ ¼å¼")


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="åˆ†æç­”æ¡ˆæ ¼å¼é—®é¢˜")
    parser.add_argument("--exp_id", type=str, default="zebralogic_practice_medium30_1", help="å®éªŒID")
    parser.add_argument("--sample_id", type=int, help="åˆ†æç‰¹å®šæ ·æœ¬ï¼ˆä»1å¼€å§‹ï¼‰")
    parser.add_argument("--limit", type=int, default=10, help="åˆ†æçš„æ ·æœ¬æ•°é‡")
    parser.add_argument("--detailed", action="store_true", help="æ˜¾ç¤ºè¯¦ç»†åˆ†æ")
    
    args = parser.parse_args()
    
    engine = SQLModelUtils.get_engine()
    
    # å¦‚æœæŒ‡å®šäº†æ ·æœ¬IDï¼Œè¯¦ç»†åˆ†æè¯¥æ ·æœ¬
    if args.sample_id:
        with Session(engine) as session:
            stmt = select(EvaluationSample).where(
                EvaluationSample.exp_id == args.exp_id
            ).limit(args.limit)
            
            samples = list(session.exec(stmt).all())
            
            if args.sample_id <= len(samples):
                analyze_single_sample(samples[args.sample_id - 1], args.sample_id)
            else:
                print(f"æ ·æœ¬ {args.sample_id} ä¸å­˜åœ¨ï¼ˆæ€»å…± {len(samples)} ä¸ªæ ·æœ¬ï¼‰")
    
    # è¯¦ç»†æ¨¡å¼ï¼šé€ä¸ªåˆ†æ
    elif args.detailed:
        with Session(engine) as session:
            stmt = select(EvaluationSample).where(
                EvaluationSample.exp_id == args.exp_id
            ).where(
                EvaluationSample.reward < 1.0
            ).limit(args.limit)
            
            samples = list(session.exec(stmt).all())
            
            for i, sample in enumerate(samples, 1):
                analyze_single_sample(sample, i)
                if i < len(samples):
                    input("\næŒ‰ Enter ç»§ç»­ä¸‹ä¸€ä¸ªæ ·æœ¬...")
    
    # é»˜è®¤ï¼šæ ¼å¼ç»Ÿè®¡
    else:
        compare_answer_formats(args.exp_id, limit=args.limit)


if __name__ == "__main__":
    main()

