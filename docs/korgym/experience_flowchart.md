# KORGym 经验总结流程图 📊

## 🎯 完整流程一览

```
┌─────────────────────────────────────────────────────────────────────┐
│                      KORGym 分层经验学习系统                          │
└─────────────────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────────────────┐
│  阶段 1: 游戏对局 (Game Playing)                                     │
├─────────────────────────────────────────────────────────────────────┤
│                                                                       │
│   ┌──────────┐      ┌──────────┐      ┌──────────┐                 │
│   │  Agent   │ ───> │  KORGym  │ ───> │   游戏    │                 │
│   │          │      │ Adapter  │      │   轨迹    │                 │
│   └──────────┘      └──────────┘      └──────────┘                 │
│                                             │                         │
│                                             ↓                         │
│   输出: {game_name, seed, success, score, trajectory, rounds}        │
│                                                                       │
└─────────────────────────────────────────────────────────────────────┘
                                ↓
┌─────────────────────────────────────────────────────────────────────┐
│  阶段 2: L0 经验提取 (Experience Extraction)                         │
├─────────────────────────────────────────────────────────────────────┤
│                                                                       │
│   游戏轨迹 + Prompt 模板                                              │
│         ↓                                                             │
│   ┌─────────────────┐                                                │
│   │  LLM 分析        │                                                │
│   │  (OpenAI/etc)   │                                                │
│   └─────────────────┘                                                │
│         ↓                                                             │
│   L0 经验: "[L0-Case] 具体的成功/失败经验..."                         │
│                                                                       │
│   存储: {id: "L0_0", content: "...", game_name, score, ...}         │
│                                                                       │
└─────────────────────────────────────────────────────────────────────┘
                                ↓
┌─────────────────────────────────────────────────────────────────────┐
│  阶段 3: L1 经验聚合 (Pattern Aggregation)                           │
├─────────────────────────────────────────────────────────────────────┤
│                                                                       │
│   积累 5 个 L0 经验 (阈值可配置)                                      │
│         ↓                                                             │
│   ┌─────────────────────────────────────────────┐                   │
│   │  L0_0  L0_1  L0_2  L0_3  L0_4                │                   │
│   │   │     │     │     │     │                  │                   │
│   │   └─────┴─────┴─────┴─────┘                  │                   │
│   │            ↓                                  │                   │
│   │   ┌─────────────────┐                        │                   │
│   │   │  LLM 聚合分析   │                        │                   │
│   │   └─────────────────┘                        │                   │
│   │            ↓                                  │                   │
│   │   L1 经验: "[L1-Pattern] 通用策略模式..."     │                   │
│   └─────────────────────────────────────────────┘                   │
│                                                                       │
│   存储: {id: "L1_0", content: "...",                                 │
│          source_l0_ids: ["L0_0"..."L0_4"]}                          │
│                                                                       │
└─────────────────────────────────────────────────────────────────────┘
                                ↓
┌─────────────────────────────────────────────────────────────────────┐
│  阶段 4: L2 经验聚合 (Meta-Strategy Synthesis)                       │
├─────────────────────────────────────────────────────────────────────┤
│                                                                       │
│   积累 3 个 L1 经验 + 对应的 15 个 L0 (双重输入)                      │
│         ↓                                                             │
│   ┌─────────────────────────────────────────────┐                   │
│   │  L1_0  L1_1  L1_2   (3 个模式)               │                   │
│   │   │     │     │                              │                   │
│   │   ├─────┼─────┤                              │                   │
│   │   ↓     ↓     ↓                              │                   │
│   │  L0_0...L0_4  L0_5...L0_9  L0_10...L0_14    │                   │
│   │  (对应的 15 个具体案例)                       │                   │
│   │   │                                           │                   │
│   │   └──────────────┬──────────────┘            │                   │
│   │                  ↓                            │                   │
│   │   ┌─────────────────────────┐                │                   │
│   │   │  LLM 元策略提取         │                │                   │
│   │   │  (同时考虑 L1 和 L0)    │                │                   │
│   │   └─────────────────────────┘                │                   │
│   │                  ↓                            │                   │
│   │   L2 经验: "[L2-Meta] 元原则: ..."           │                   │
│   └─────────────────────────────────────────────┘                   │
│                                                                       │
│   存储: {id: "L2_0", content: "...",                                 │
│          source_l1_ids: ["L1_0"..."L1_2"],                          │
│          source_l0_ids: ["L0_0"..."L0_14"]}                         │
│                                                                       │
└─────────────────────────────────────────────────────────────────────┘
                                ↓
┌─────────────────────────────────────────────────────────────────────┐
│  阶段 5: Agent 配置增强 (Agent Enhancement)                          │
├─────────────────────────────────────────────────────────────────────┤
│                                                                       │
│   ┌─────────────────────────────────────────────┐                   │
│   │  Agent 原始配置                              │                   │
│   │  instructions: "Solve the game..."          │                   │
│   └─────────────────────────────────────────────┘                   │
│                  ↓                                                    │
│   注入分层经验 (L2 → L1 → L0)                                         │
│                  ↓                                                    │
│   ┌─────────────────────────────────────────────┐                   │
│   │  增强后的 Agent 配置                         │                   │
│   │  instructions: |                            │                   │
│   │    "Solve the game..."                      │                   │
│   │                                              │                   │
│   │    When playing, read these experiences:    │                   │
│   │    [G0]. [L2-Meta] Principle: ...           │                   │
│   │    [G1]. [L1-Pattern] Strategy: ...         │                   │
│   │    [G2]. [L1-Pattern] Tactic: ...           │                   │
│   │    [G3]. [L0-Case] Specific: ...            │                   │
│   │    ...                                       │                   │
│   └─────────────────────────────────────────────┘                   │
│                  ↓                                                    │
│   保存到: configs/agents/practice/korgym_xxx_agent.yaml              │
│                                                                       │
└─────────────────────────────────────────────────────────────────────┘
                                ↓
┌─────────────────────────────────────────────────────────────────────┐
│  循环: 再次游戏对局 (增强的 Agent)                                    │
├─────────────────────────────────────────────────────────────────────┤
│                                                                       │
│   增强 Agent → 更好的表现 → 新的游戏轨迹 → 更多经验 → ...            │
│                                                                       │
│   ┌──────────────────────────────────────────┐                      │
│   │         持续改进循环                      │                      │
│   │                                           │                      │
│   │   ┌───────┐    ┌──────┐    ┌───────┐    │                      │
│   │   │ 对局  │───>│ 提取 │───>│ 聚合  │    │                      │
│   │   └───────┘    └──────┘    └───────┘    │                      │
│   │       ↑                         │         │                      │
│   │       │         增强             │         │                      │
│   │       └─────────────────────────┘         │                      │
│   └──────────────────────────────────────────┘                      │
│                                                                       │
└─────────────────────────────────────────────────────────────────────┘
```

---

## 📊 数据流示例

### 示例：玩 15 局 2048 游戏

```
时间线视图:

游戏 1-5 (Batch 1)
├─ 游戏 1: 失败(512)  → L0_0: "角落策略"
├─ 游戏 2: 成功(2048) → L0_1: "保持结构"
├─ 游戏 3: 失败(1024) → L0_2: "规划合并"
├─ 游戏 4: 成功(2048) → L0_3: "边缘构建"
└─ 游戏 5: 失败(256)  → L0_4: "避免随机"
                          ↓
                    ✨ 触发 L1 聚合
                          ↓
                   L1_0: "结构保持策略"

游戏 6-10 (Batch 2)
├─ 游戏 6: 成功(2048) → L0_5: "中期管理"
├─ 游戏 7: 失败(512)  → L0_6: "灵活性"
├─ 游戏 8: 失败(1024) → L0_7: "死局识别"
├─ 游戏 9: 成功(2048) → L0_8: "大瓦片优先"
└─ 游戏 10: 成功(4096)→ L0_9: "动态调整"
                          ↓
                    ✨ 触发 L1 聚合
                          ↓
                   L1_1: "自适应规划策略"

游戏 11-15 (Batch 3)
├─ 游戏 11: 成功(2048)→ L0_10: "风险评估"
├─ 游戏 12: 失败(512) → L0_11: "平衡目标"
├─ 游戏 13: 成功(2048)→ L0_12: "避免贪婪"
├─ 游戏 14: 成功(4096)→ L0_13: "空间预留"
└─ 游戏 15: 成功(2048)→ L0_14: "局面评估"
                          ↓
                    ✨ 触发 L1 聚合
                          ↓
                   L1_2: "风险-收益分析"
                          ↓
                    ✨ 触发 L2 聚合 (3个L1 + 15个L0)
                          ↓
                   L2_0: "元原则: 系统化结构优于机会主义"
                          ↓
                    更新 Agent 配置
                          ↓
               下一轮使用增强的 Agent
```

---

## 🏗️ 系统架构

```
┌─────────────────────────────────────────────────────────────┐
│                    KORGym 游戏服务器                          │
│   (FastAPI, 端口 8775, 50+ 游戏)                             │
└─────────────────────────────────────────────────────────────┘
                            ↕ HTTP API
┌─────────────────────────────────────────────────────────────┐
│                    KORGym Adapter                            │
│  - 游戏实例生成                                               │
│  - 棋盘状态管理                                               │
│  - 动作验证                                                   │
│  - 多回合控制                                                 │
└─────────────────────────────────────────────────────────────┘
                            ↕
┌─────────────────────────────────────────────────────────────┐
│                Training-Free GRPO                            │
│  - 批次管理                                                   │
│  - Agent 执行                                                 │
│  - 轨迹收集                                                   │
└─────────────────────────────────────────────────────────────┘
                            ↕
┌─────────────────────────────────────────────────────────────┐
│           KORGym Experience Extractor                        │
│  - L0 经验提取 (使用 LLM)                                     │
│  - Prompt 模板管理                                            │
│  - 轨迹分析                                                   │
└─────────────────────────────────────────────────────────────┘
                            ↕
┌─────────────────────────────────────────────────────────────┐
│       Hierarchical Experience Manager                        │
│  - L0 存储和管理                                              │
│  - L1 聚合 (5 L0 → 1 L1)                                     │
│  - L2 聚合 (3 L1 + 15 L0 → 1 L2)                            │
│  - 经验持久化 (JSON)                                          │
└─────────────────────────────────────────────────────────────┘
                            ↕
┌─────────────────────────────────────────────────────────────┐
│               Agent Config Generator                         │
│  - 注入分层经验到 instructions                                │
│  - 生成增强的 Agent YAML                                      │
│  - 保存配置文件                                               │
└─────────────────────────────────────────────────────────────┘
```

---

## 📁 文件流转

```
┌─────────────────────────────────────────────────────────────┐
│  输入文件                                                     │
├─────────────────────────────────────────────────────────────┤
│  ✓ configs/practice/korgym_hierarchical_test.yaml           │
│    (训练配置)                                                 │
│  ✓ configs/agents/practice/logic_agent_xxx.yaml             │
│    (基础 Agent)                                               │
│  ✓ configs/prompts/hierarchical_critique.yaml               │
│    (Prompt 模板)                                              │
└─────────────────────────────────────────────────────────────┘
                            ↓  训练过程
┌─────────────────────────────────────────────────────────────┐
│  中间文件 / 日志                                              │
├─────────────────────────────────────────────────────────────┤
│  • logs/training_xxx.log (训练日志)                          │
│  • workspace/korgym_test/ (临时测试结果)                     │
└─────────────────────────────────────────────────────────────┘
                            ↓  训练完成
┌─────────────────────────────────────────────────────────────┐
│  输出文件                                                     │
├─────────────────────────────────────────────────────────────┤
│  ✓ workspace/hierarchical_experiences/korgym_2048.json      │
│    {                                                         │
│      "l0_experiences": [...],  // 50 个 L0                  │
│      "l1_experiences": [...],  // 10 个 L1                  │
│      "l2_experiences": [...]   // 3 个 L2                   │
│    }                                                         │
│                                                              │
│  ✓ configs/agents/practice/korgym_2048_agent.yaml           │
│    (增强后的 Agent 配置，包含所有经验)                        │
│                                                              │
│  ✓ database.db (SQLite)                                     │
│    (评估结果、性能指标)                                       │
└─────────────────────────────────────────────────────────────┘
```

---

## 🔄 典型训练循环

```
┌────────────────────────────────────────────────────────────┐
│  Epoch 1, Batch 1                                           │
├────────────────────────────────────────────────────────────┤
│  Agent: 基础 Agent (无经验)                                 │
│  游戏: 5 局                                                  │
│  L0: 5 个                                                    │
│  L1: 1 个 ✨                                                 │
│  L2: 0 个                                                    │
│  平均分: 1024                                                │
└────────────────────────────────────────────────────────────┘
                      ↓
┌────────────────────────────────────────────────────────────┐
│  Epoch 1, Batch 2                                           │
├────────────────────────────────────────────────────────────┤
│  Agent: 基础 Agent + 1 L1 + 5 L0                            │
│  游戏: 5 局                                                  │
│  L0: 10 个 (累计)                                            │
│  L1: 2 个 ✨                                                 │
│  L2: 0 个                                                    │
│  平均分: 1536 ↑                                              │
└────────────────────────────────────────────────────────────┘
                      ↓
┌────────────────────────────────────────────────────────────┐
│  Epoch 2, Batch 1                                           │
├────────────────────────────────────────────────────────────┤
│  Agent: 基础 Agent + 2 L1 + 10 L0                           │
│  游戏: 5 局                                                  │
│  L0: 15 个 (累计)                                            │
│  L1: 3 个 ✨                                                 │
│  L2: 1 个 ✨✨ (重要里程碑!)                                  │
│  平均分: 2048 ↑↑                                             │
└────────────────────────────────────────────────────────────┘
                      ↓
┌────────────────────────────────────────────────────────────┐
│  Epoch 2, Batch 2                                           │
├────────────────────────────────────────────────────────────┤
│  Agent: 基础 Agent + 1 L2 + 3 L1 + 15 L0                    │
│  游戏: 5 局                                                  │
│  L0: 20 个 (累计)                                            │
│  L1: 4 个 ✨                                                 │
│  L2: 1 个                                                    │
│  平均分: 2560 ↑↑↑                                            │
└────────────────────────────────────────────────────────────┘
                      ↓
┌────────────────────────────────────────────────────────────┐
│  Epoch 3                                                    │
├────────────────────────────────────────────────────────────┤
│  Agent: 全面增强 (1 L2 + 4 L1 + 20 L0)                      │
│  持续改进...                                                 │
│  平均分: 3072+ ↑↑↑↑                                          │
└────────────────────────────────────────────────────────────┘
```

---

## 🎯 关键节点

### 触发点 1: L1 生成
```
条件: 积累 5 个未聚合的 L0
操作: LLM 分析 → 生成 1 个 L1
效果: 从具体案例中提取通用模式
```

### 触发点 2: L2 生成
```
条件: 积累 3 个 L1 (对应 15 个 L0)
操作: LLM 分析 (L1 + L0 双重输入) → 生成 1 个L2
效果: 从多个模式中提取元认知原则
```

### 触发点 3: Agent 更新
```
条件: 每次生成新的 L1 或 L2
操作: 重新生成 Agent 配置
效果: Agent 获得最新经验，性能提升
```

---

## 📈 性能提升曲线

```
平均分数
 4096 |                               ╱─────
      |                          ╱────
 3072 |                     ╱────
      |                ╱────    ← L2 生成后加速
 2048 |           ╱────
      |      ╱────     ← L1 积累阶段
 1024 | ────          ← 基础阶段
      |
    0 └─────┬─────┬─────┬─────┬─────┬─────→ 游戏局数
           0    10    20    30    40    50
                      ↑           ↑
                   第1个L2     第2个L2
```

---

## 🔧 配置参数影响

```
┌──────────────────────────────────────────────────────────┐
│  参数: l1_aggregation_threshold                           │
├──────────────────────────────────────────────────────────┤
│  • 设为 3: 更频繁生成 L1，但可能不够通用                  │
│  • 设为 5: 平衡 ✓ (推荐)                                  │
│  • 设为 10: 更通用的 L1,但生成慢                          │
└──────────────────────────────────────────────────────────┘

┌──────────────────────────────────────────────────────────┐
│  参数: l2_aggregation_threshold                           │
├──────────────────────────────────────────────────────────┤
│  • 设为 2: 快速生成 L2，但可能过早抽象                    │
│  • 设为 3: 平衡 ✓ (推荐)                                  │
│  • 设为 5: 更稳健的 L2，但需更多数据                      │
└──────────────────────────────────────────────────────────┘

┌──────────────────────────────────────────────────────────┐
│  参数: max_l0_recent                                      │
├──────────────────────────────────────────────────────────┤
│  • 设为 10: Prompt 短，但信息少                           │
│  • 设为 30: 平衡 ✓ (推荐)                                 │
│  • 设为 50: 信息丰富，但 Prompt 长                        │
└──────────────────────────────────────────────────────────┘
```

---

## 🎊 总结

KORGym 经验总结是一个**自动化、分层化、智能化**的学习系统：

```
🎮 玩游戏 → 📝 提取经验 → 🧠 聚合知识 → 🚀 增强 Agent → 🔄 循环提升
```

**核心创新点**：
1. **三层架构**: L0/L1/L2 清晰分层
2. **双重输入**: L2 生成同时考虑 L1 和 L0
3. **自动触发**: 基于阈值自动生成高层经验
4. **持续改进**: Agent 不断学习和进化

🎯 **最终目标**: 让 Agent 从游戏实践中自主学习，形成可迁移的通用智能！











